{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Full Training and Explanation Example\n\nThis notebook demonstrates MEGAN's complete workflow including multi-channel explanation extraction and visualization. Building on the basic usage example, this notebook focuses on MEGAN's unique explainability features and the systematic analysis of attention-based explanations.\n\n## MEGAN's Multi-Channel Architecture in Practice\n\n**Dual-Channel Regression**: For regression tasks, MEGAN employs two explanation channels that learn to identify molecular features contributing positively and negatively to the target property. This separation provides more nuanced explanations than single-attention mechanisms.\n\n**Explanation Co-Training**: During training, MEGAN simultaneously optimizes prediction accuracy and explanation consistency through self-supervised learning, ensuring that attention weights capture genuine molecular relationships rather than spurious correlations.\n\n**Attention-Based Interpretability**: Unlike post-hoc explanation methods, MEGAN's explanations are generated during the forward pass as an integral part of the prediction process, making them more reliable and computationally efficient."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🧪 Dataset Loading and Splitting\n\nWe'll prepare train and test datasets to evaluate MEGAN's performance and extract explanations from test samples."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from rich.pretty import pprint\n",
    "\n",
    "plt.style.use('default')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- loading the dataset ---\n# Load the molecular dataset - same as basic example\nPATH: str = os.getcwd()\nDATASET_PATH: str = os.path.join(PATH, \"clogp.csv\")\n\ndataset: pd.DataFrame = pd.read_csv(DATASET_PATH)\n\nprint('Dataset size:', len(dataset))\nprint('\\nDataset preview:')\nprint(dataset.head())\n\n# --- train-test split ---\n# Create a reproducible train-test split for unbiased performance evaluation\nrandom.seed(42)\nnp.random.seed(42)\n\n# Split into 80% train, 20% test\nindices = list(range(len(dataset)))\ntest_size = int(0.2 * len(dataset))\ntest_indices = random.sample(indices, k=test_size)\ntrain_indices = [i for i in indices if i not in test_indices]\n\ntrain_dataset = dataset.iloc[train_indices].copy()\ntest_dataset = dataset.iloc[test_indices].copy()\n\n# Save split datasets for reproducibility and potential reuse\nTRAIN_PATH = os.path.join(PATH, \"train_clogp.csv\")\nTEST_PATH = os.path.join(PATH, \"test_clogp.csv\")\n\ntrain_dataset.to_csv(TRAIN_PATH, index=False)\ntest_dataset.to_csv(TEST_PATH, index=False)\n\nprint(f'\\nTrain set size: {len(train_dataset)}')\nprint(f'Test set size: {len(test_dataset)}')\nprint(f'Train set saved to: {TRAIN_PATH}')\nprint(f'Test set saved to: {TEST_PATH}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ⚙️ Dataset Processing\n\nWe'll use the same MoleculeProcessing pipeline to ensure consistency with the basic example. This processing converts SMILES strings to graph dictionaries that MEGAN can process."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from visual_graph_datasets.processing.molecules import MoleculeProcessing\n\n# Initialize the molecular processing pipeline - same as basic example\nprocessing = MoleculeProcessing()\n\n# Test the processing with a sample molecule to verify setup\nSAMPLE_SMILES = 'C1=CC=C2C=C(CCN)C=CC2=C1'\nsample_graph: dict = processing.process(SAMPLE_SMILES)\n\nprint('Graph attributes:')\npprint(list(sample_graph.keys()))\nprint(f'\\nNumber of nodes: {len(sample_graph[\"node_attributes\"])}')\nprint(f'Number of edges: {len(sample_graph[\"edge_attributes\"])}')\nprint(f'Node features dimension: {processing.get_num_node_attributes()}')\nprint(f'Edge features dimension: {processing.get_num_edge_attributes()}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🤖 MEGAN Model Configuration\n\nHere we configure MEGAN with explanation capabilities enabled. The key parameters that distinguish MEGAN from standard GNNs are the explanation-related settings that enable the dual-channel attention mechanism and co-training objectives."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pytorch_lightning as pl\nfrom torch_geometric.loader import DataLoader\nfrom graph_attention_student import Megan, SmilesDataset\n\n# --- MEGAN configuration for explainable predictions ---\nmodel = Megan(\n    # Input dimensions must match the MoleculeProcessing output\n    node_dim=processing.get_num_node_attributes(),\n    edge_dim=processing.get_num_edge_attributes(),\n    \n    # Graph encoder architecture - deeper networks can capture more complex patterns\n    units=[64, 64, 64],  # Three message-passing layers for hierarchical feature learning\n    final_units=[64, 32, 1],  # Prediction MLP: embedding -> intermediate -> single logP value\n    \n    # Task configuration for regression\n    prediction_mode='regression',\n    learning_rate=1e-4,\n    \n    # --- MEGAN's unique explanation configuration ---\n    importance_mode='regression',  # Explanation channels tailored for continuous targets\n    \n    # KEY: importance_factor > 0 activates explanation co-training\n    # This forces attention weights to be predictive of the target independently\n    # Higher values prioritize explanation quality over pure prediction accuracy\n    importance_factor=1.0,\n    \n    # Sparsity regularization prevents the model from highlighting everything as \"important\"\n    # This promotes focused, interpretable explanations rather than diffuse attention\n    sparsity_factor=0.5,\n    \n    # Controls the baseline attention level - affects explanation granularity\n    # Higher values create more sparse (selective) explanations\n    importance_offset=1.0,\n    \n    # For regression: 2 channels capture positive and negative evidence separately\n    # This dual-channel approach provides more nuanced explanations than single attention\n    num_channels=2,\n)\n\nprint('MEGAN model configured with explanation capabilities:')\nprint(f'- Explanation channels: {model.num_channels}')\nprint(f'- Explanation co-training factor: {model.importance_factor}')\nprint(f'- Sparsity regularization factor: {model.sparsity_factor}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- Training with SmilesDataset for efficient molecular data streaming ---\n# SmilesDataset provides lazy loading and on-the-fly graph conversion\n# This is memory-efficient for large molecular datasets\ntrain_smiles_dataset = SmilesDataset(\n    dataset=TRAIN_PATH,\n    smiles_column='smiles',\n    target_columns=['value'],\n    processing=processing,  # Must use the same processing pipeline for consistency\n    reservoir_sampling=True,  # Enables proper shuffling without loading entire dataset\n)\n\n# Configure DataLoader for batch processing\ntrain_loader = DataLoader(\n    train_smiles_dataset,\n    batch_size=64,  # Balanced for stable gradients and memory efficiency\n    drop_last=True,  # Prevents BatchNorm issues with variable-sized final batches\n    num_workers=4,   # Parallel SMILES->graph conversion\n    prefetch_factor=2,  # Pre-load batches to hide processing latency\n)\n\n# --- MEGAN training with multi-objective optimization ---\ntrainer = pl.Trainer(\n    max_epochs=150,  # Extended training needed for explanation convergence\n    accelerator='auto',\n    devices='auto',\n)\n\nprint('Starting MEGAN training with explanation co-training...')\nprint('Training objectives:')\nprint('1. Prediction accuracy (MSE loss)')\nprint('2. Explanation consistency (importance_factor * explanation_loss)')  \nprint('3. Attention sparsity (sparsity_factor * sparsity_loss)')\n\ntrainer.fit(model, train_dataloaders=train_loader)\nmodel.eval()  # Critical: switch to evaluation mode for consistent inference\nprint('MEGAN training completed with explanation capabilities!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 📊 MEGAN Performance Evaluation\n\nWe evaluate the trained model on unseen test data to assess both prediction accuracy and the reliability of the explanation mechanism."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- Evaluate MEGAN on both training and test sets ---\n# This compares performance on seen vs unseen data to assess overfitting\ntrain_predictions = []\ntrain_targets = []\n\nprint('Evaluating MEGAN on training set...')\nfor idx, row in train_dataset.iterrows():\n    smiles = row['smiles']\n    target = row['value']\n    \n    try:\n        graph = processing.process(smiles)\n        result = model.forward_graph(graph)\n        prediction = result['graph_output'].item()\n        \n        train_predictions.append(prediction)\n        train_targets.append(target)\n        \n    except Exception as e:\n        print(f'Skipping molecule {smiles}: {e}')\n        continue\n\ntrain_predictions = np.array(train_predictions)\ntrain_targets = np.array(train_targets)\n\n# Evaluate on test set\ntest_predictions = []\ntest_targets = []\ntest_smiles_list = []\n\nprint('Evaluating MEGAN on test set...')\nfor idx, row in test_dataset.iterrows():\n    smiles = row['smiles']\n    target = row['value']\n    \n    try:\n        graph = processing.process(smiles)\n        result = model.forward_graph(graph)\n        prediction = result['graph_output'].item()\n        \n        test_predictions.append(prediction)\n        test_targets.append(target)\n        test_smiles_list.append(smiles)\n        \n    except Exception as e:\n        print(f'Skipping molecule {smiles}: {e}')\n        continue\n\ntest_predictions = np.array(test_predictions)\ntest_targets = np.array(test_targets)\n\n# Calculate metrics for both sets\ntrain_mse = mean_squared_error(train_targets, train_predictions)\ntrain_mae = mean_absolute_error(train_targets, train_predictions)\ntrain_r2 = r2_score(train_targets, train_predictions)\ntrain_rmse = np.sqrt(train_mse)\n\ntest_mse = mean_squared_error(test_targets, test_predictions)\ntest_mae = mean_absolute_error(test_targets, test_predictions)\ntest_r2 = r2_score(test_targets, test_predictions)\ntest_rmse = np.sqrt(test_mse)\n\nprint(f'\\nMEGAN Training Set Performance:')\nprint(f'Samples: {len(train_predictions)} | RMSE: {train_rmse:.4f} | MAE: {train_mae:.4f} | R²: {train_r2:.4f}')\n\nprint(f'\\nMEGAN Test Set Performance:')\nprint(f'Samples: {len(test_predictions)} | RMSE: {test_rmse:.4f} | MAE: {test_mae:.4f} | R²: {test_r2:.4f}')\n\n# Create side-by-side regression plots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Training set plot (red)\nax1.scatter(train_targets, train_predictions, alpha=0.6, color='red', s=20)\ntrain_range = [train_targets.min(), train_targets.max()]\nax1.plot(train_range, train_range, 'k--', lw=2)\nax1.set_xlabel('True cLogP')\nax1.set_ylabel('Predicted cLogP')\nax1.set_title(f'Training Set (n={len(train_predictions)})\\nRMSE: {train_rmse:.3f} | MAE: {train_mae:.3f} | R²: {train_r2:.3f}')\nax1.grid(True, alpha=0.3)\nax1.set_aspect('equal', adjustable='box')\n\n# Test set plot (blue)\nax2.scatter(test_targets, test_predictions, alpha=0.6, color='blue', s=20)\ntest_range = [test_targets.min(), test_targets.max()]\nax2.plot(test_range, test_range, 'k--', lw=2)\nax2.set_xlabel('True cLogP')\nax2.set_ylabel('Predicted cLogP')\nax2.set_title(f'Test Set (n={len(test_predictions)})\\nRMSE: {test_rmse:.3f} | MAE: {test_mae:.3f} | R²: {test_r2:.3f}')\nax2.grid(True, alpha=0.3)\nax2.set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🔍 Extracting MEGAN's Multi-Channel Explanations\n\nNow we demonstrate how to extract and interpret MEGAN's dual-channel attention mechanisms. Unlike standard GNNs, MEGAN provides separate importance scores for positive and negative evidence, enabling more detailed analysis of model reasoning."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Select representative examples for explanation analysis\nnp.random.seed(42)\nexplanation_indices = np.random.choice(len(test_smiles_list), size=10, replace=False)\n\nprint(f'Selected {len(explanation_indices)} examples for MEGAN explanation analysis:')\nfor i, idx in enumerate(explanation_indices):\n    smiles = test_smiles_list[idx]\n    target = test_targets[idx]\n    prediction = test_predictions[idx]\n    print(f'{i+1}. SMILES: {smiles[:50]}... | True: {target:.3f} | Pred: {prediction:.3f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Function to normalize MEGAN's importance values for consistent visualization\ndef normalize_importances(importances):\n    \"\"\"\n    Normalize MEGAN importance values to [0, 1] range for consistent visualization.\n    This ensures that attention weights are comparable across different molecules\n    and channels, enabling meaningful visual comparisons.\n    \"\"\"\n    min_val = np.min(importances)\n    max_val = np.max(importances)\n    if max_val > min_val:\n        return (importances - min_val) / (max_val - min_val)\n    else:\n        return np.zeros_like(importances)\n\n# Extract MEGAN's dual-channel explanations for selected molecules\nexplanation_results = []\n\nprint('Extracting MEGAN explanations...')\nfor idx in explanation_indices:\n    smiles = test_smiles_list[idx]\n    target = test_targets[idx]\n    prediction = test_predictions[idx]\n    \n    # Process molecule and extract full MEGAN output including attention weights\n    graph = processing.process(smiles)\n    result = model.forward_graph(graph)\n    \n    # MEGAN's key outputs:\n    # - node_importance: (num_nodes, num_channels) - attention weights for each atom\n    # - edge_importance: (num_edges, num_channels) - attention weights for each bond\n    node_importance = result['node_importance']\n    edge_importance = result['edge_importance']\n    \n    # Normalize for consistent visualization across molecules\n    node_importance_norm = normalize_importances(node_importance)\n    edge_importance_norm = normalize_importances(edge_importance)\n    \n    explanation_results.append({\n        'smiles': smiles,\n        'target': target,\n        'prediction': prediction,\n        'graph': graph,\n        'node_importance': node_importance_norm,  # Shape: (num_atoms, 2) for dual channels\n        'edge_importance': edge_importance_norm,  # Shape: (num_bonds, 2) for dual channels\n    })\n\nprint(f'Extracted MEGAN explanations for {len(explanation_results)} molecules.')\nprint(f'Each explanation has {explanation_results[0][\"node_importance\"].shape[1]} attention channels.')\nprint('Channel 0: Features contributing negatively to logP (hydrophilic)')  \nprint('Channel 1: Features contributing positively to logP (hydrophobic)')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 🎨 Visualizing MEGAN's Dual-Channel Explanations\n\nMEGAN's visualization system overlays attention-based importance maps onto molecular structures. The dual-channel approach separates positive and negative evidence, providing clearer interpretation of model reasoning than single-channel attention mechanisms."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from visual_graph_datasets.visualization.importances import plot_node_importances_background\nfrom visual_graph_datasets.visualization.importances import plot_edge_importances_background\nfrom visual_graph_datasets.visualization.base import draw_image\nimport tempfile\n\n# Create comprehensive visualization showing MEGAN's dual-channel explanations\nnum_examples = len(explanation_results)\nnum_channels = 2  # MEGAN's dual channels for regression\nfig_width = 4 * (num_channels + 1)  # Original molecule + 2 explanation channels\nfig_height = 3 * num_examples\n\nfig, axes = plt.subplots(\n    nrows=num_examples, \n    ncols=num_channels + 1,  # Molecular structure + dual explanation channels\n    figsize=(fig_width, fig_height)\n)\n\n# Ensure axes is always 2D for consistent indexing\nif num_examples == 1:\n    axes = axes.reshape(1, -1)\n\n# Color scheme for MEGAN's dual channels\nchannel_colors = ['royalblue', 'orangered']  # Blue for negative, red for positive  \nchannel_labels = ['Hydrophilic Evidence', 'Hydrophobic Evidence']\n\nprint('Creating MEGAN explanation visualizations...')\nfor row, result in enumerate(explanation_results):\n    smiles = result['smiles']\n    target = result['target']\n    prediction = result['prediction']\n    graph = result['graph']\n    node_importance = result['node_importance']\n    edge_importance = result['edge_importance']\n    \n    # Generate molecular structure visualization using MoleculeProcessing\n    mol_fig, node_positions = processing.visualize_as_figure(smiles, width=400, height=400)\n    # Coordinate transformation for matplotlib compatibility\n    node_positions[:, 1] = 400 - node_positions[:, 1]  # Invert y-axis for proper overlay alignment\n    \n    # Save molecular visualization for overlay operations\n    temp_file = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n    mol_fig.savefig(temp_file.name)\n    temp_file.close()\n    \n    # Store node positions in graph dict for visualization functions\n    graph['node_positions'] = node_positions\n    \n    # Column 0: Original molecular structure\n    ax_orig = axes[row, 0]\n    ax_orig.imshow(np.array(mol_fig.canvas.renderer.buffer_rgba()))\n    ax_orig.set_title(f'Molecule {row+1}\\nTrue: {target:.3f}, Pred: {prediction:.3f}')\n    ax_orig.axis('off')\n    \n    # Columns 1-2: MEGAN's dual explanation channels\n    for channel in range(num_channels):\n        ax = axes[row, channel + 1]\n        \n        # Draw base molecular structure\n        ax.imshow(np.array(mol_fig.canvas.renderer.buffer_rgba()))\n        \n        # Overlay MEGAN's node importance (atomic contributions)\n        # Higher intensity = greater importance in this channel\n        plot_node_importances_background(\n            ax=ax,\n            g=graph,\n            node_positions=node_positions,\n            node_importances=node_importance[:, channel],\n            color=channel_colors[channel],\n            radius=20,  # Size of importance circles around atoms\n            v_min=0,\n            v_max=1,\n        )\n        \n        # Overlay MEGAN's edge importance (bond contributions) \n        # Line thickness/opacity indicates bond importance\n        plot_edge_importances_background(\n            ax=ax,\n            g=graph,\n            node_positions=node_positions,\n            edge_importances=edge_importance[:, channel],\n            color=channel_colors[channel],\n            thickness=10,  # Width of importance lines over bonds\n            v_min=0,\n            v_max=1,\n        )\n        \n        ax.set_title(f'{channel_labels[channel]}')\n        ax.axis('off')\n    \n    plt.close(mol_fig)  # Clean up temporary figure\n\nplt.tight_layout()\nplt.suptitle('MEGAN Dual-Channel Explanations for Test Molecules', y=1.02, fontsize=16)\nplt.show()\n\nprint('\\nExplanation Guide:')\nprint('• Blue highlights: Molecular features that decrease logP (increase hydrophilicity)')\nprint('• Red highlights: Molecular features that increase logP (increase hydrophobicity)')\nprint('• Intensity indicates the strength of contribution according to MEGAN attention weights')\nprint('• Both atoms (circles) and bonds (lines) can contribute to the final prediction')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 📋 MEGAN Analysis Summary\n\nThis notebook demonstrated MEGAN's complete explainable AI workflow for molecular property prediction:\n\n## Key MEGAN Features Demonstrated:\n\n### 1. **Multi-Objective Training**\n- **Prediction accuracy**: Standard regression loss for logP values\n- **Explanation consistency**: Self-supervised loss ensuring attention weights are predictive\n- **Sparsity regularization**: Promotes focused, interpretable explanations\n\n### 2. **Dual-Channel Architecture** \n- **Channel separation**: Distinct attention mechanisms for positive/negative evidence\n- **Chemical relevance**: Hydrophobic vs. hydrophilic feature identification\n- **Nuanced explanations**: More detailed than single-attention approaches\n\n### 3. **Integrated Explanation Generation**\n- **Forward-pass explanations**: Generated during prediction, not post-hoc\n- **Node and edge importance**: Both atomic and bonding contributions captured\n- **Visualization-ready output**: Direct integration with molecular structure displays\n\n## Advantages Over Standard GNNs:\n\n**Interpretability**: MEGAN explanations reveal *why* predictions are made, not just *what* is predicted.\n\n**Chemical Validity**: Attention weights align with known structure-property relationships in chemistry.\n\n**Reliability**: Co-training ensures explanations genuinely affect predictions rather than being mere visualizations.\n\n**Efficiency**: Explanations are generated simultaneously with predictions, requiring no additional computational overhead during inference.\n\nThis explainable AI approach makes MEGAN particularly valuable for scientific applications where understanding model reasoning is crucial for hypothesis generation, experimental design, and regulatory approval processes."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}